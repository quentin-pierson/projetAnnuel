{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ccd207",
   "metadata": {},
   "source": [
    "# <center> <span style=\"color:red\">Music recognition </span> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440cabe",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to take in music spectrograms and to recognize musical genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b6ec6",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3faa6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb785e99",
   "metadata": {},
   "source": [
    "## Import Model Linear and MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7621ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../../python')\n",
    "\n",
    "from linearModel import linearModel\n",
    "from mlp import MLPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ccd7c3",
   "metadata": {},
   "source": [
    "## Create Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b047493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linearModel()\n",
    "mlp = MLPModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd54240",
   "metadata": {},
   "source": [
    "## Algorithme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f50c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_images_and_assign_labels(\n",
    "        folder, label, X, Y):\n",
    "    for file in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file)\n",
    "        im = Image.open(image_path)\n",
    "        im = im.resize((8, 8))\n",
    "        im = im.convert(\"RGB\")\n",
    "        im_arr = np.array(im)\n",
    "        im_arr = np.reshape(im_arr, (8 * 8 * 3))\n",
    "        X.append(im_arr)\n",
    "        Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8223667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset():\n",
    "    dataset_folder = \"G:/Programmes/Python/projetAnnuel/data\"\n",
    "    train_folder = os.path.join(dataset_folder, \"train\")\n",
    "    test_folder = os.path.join(dataset_folder, \"test\")\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    import_images_and_assign_labels(\n",
    "        os.path.join(train_folder, \"Electro\"), 1.0, X_train, y_train\n",
    "    )\n",
    "    import_images_and_assign_labels(\n",
    "        os.path.join(train_folder, \"Metal\"), -1.0, X_train, y_train\n",
    "    )\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    import_images_and_assign_labels(\n",
    "        os.path.join(test_folder, \"Electro\"), -1.0, X_test, y_test\n",
    "    )\n",
    "    import_images_and_assign_labels(\n",
    "        os.path.join(test_folder, \"Metal\"), 1.0, X_test, y_test\n",
    "    )\n",
    "\n",
    "    return (np.array(X_train) / 255.0, np.array(y_train)), \\\n",
    "           (np.array(X_test) / 255.0, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5afd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_value(number,array):\n",
    "    print(\"Sur le dataset de Train\")\n",
    "    cpt = 0\n",
    "    for i in array:\n",
    "        print(cpt,\" \",i)\n",
    "        cpt+=1\n",
    "        if(cpt==number):\n",
    "            cpt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a87c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp():\n",
    "    (X_train, y_train), (X_test, y_test) = import_dataset()\n",
    "\n",
    "    \n",
    "    resultat1 = mlp.create_mlp_model([2,4,4,1])\n",
    "    model1 = resultat1[0]\n",
    "       \n",
    "    \n",
    "    flattened_dataset_inputs = []\n",
    "    for p in X_train:\n",
    "        flattened_dataset_inputs.append(p[0])\n",
    "        flattened_dataset_inputs.append(p[1])\n",
    "        \n",
    "    print(\"flattened_dataset_inputs\",flattened_dataset_inputs)\n",
    "    \n",
    "    print(\"X_train\",X_train[0])\n",
    "    print(\"type X_train\",type(X_train))\n",
    "    print(\"Dimension X_train\",X_train.shape)\n",
    "    print(\"\\n\")\n",
    "    mlp.train_classification_stochastic_gradient_backpropagation(model1,\n",
    "                                                                flattened_dataset_inputs,\n",
    "                                                                y_train,\n",
    "                                                                alpha=0.01,\n",
    "                                                                iterations_count=5000)\n",
    "\n",
    "    predicted_outputs = [mlp.predict_mlp_model_classification(model1, p) for p in X_train]\n",
    "       \n",
    "    display_value(160,predicted_outputs)\n",
    "    \n",
    "    mlp.free_MLP(resultat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5813ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear():\n",
    "    (X_train, y_train), (X_test, y_test) = import_dataset()\n",
    "    \n",
    "    resultat2 = lm.create_linear_model(2)\n",
    "    model2 = resultat2[0]\n",
    "\n",
    "\n",
    "    flattened_dataset_inputs = []\n",
    "    for p in X_train:\n",
    "        flattened_dataset_inputs.append(p[0])\n",
    "        flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "    lm.train_classification_rosenblatt_rule_linear_model(model2, flattened_dataset_inputs,\n",
    "                                                            y_train, 0.01,100000)\n",
    "\n",
    "    predicted_outputs = [lm.predict_linear_model_classification(model2, p) for p in X_train]\n",
    "    \n",
    "    display_value(160,predicted_outputs)\n",
    "    \n",
    "    lm.destroy_linear_model(resultat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395a8941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened_dataset_inputs [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "X_train [0.33333333 0.33333333 0.66666667 0.21960784 0.25882353 0.66666667\n",
      " 0.2        0.26666667 0.66666667 0.2        0.26666667 0.66666667\n",
      " 0.2        0.26666667 0.66666667 0.21960784 0.25882353 0.66666667\n",
      " 0.4        0.         0.2        0.         0.         0.\n",
      " 0.19215686 0.22745098 0.57647059 0.22352941 0.29411765 0.7372549\n",
      " 0.23137255 0.29803922 0.75686275 0.22745098 0.29411765 0.74509804\n",
      " 0.23137255 0.29803922 0.75686275 0.23137255 0.29019608 0.7254902\n",
      " 0.52156863 0.25882353 0.38039216 0.         0.         0.\n",
      " 0.16862745 0.20392157 0.54901961 0.21176471 0.28235294 0.74117647\n",
      " 0.22352941 0.29411765 0.77254902 0.21960784 0.29019608 0.76078431\n",
      " 0.22352941 0.29411765 0.77254902 0.22745098 0.29019608 0.74509804\n",
      " 0.58431373 0.41176471 0.49803922 0.         0.         0.\n",
      " 0.21176471 0.31764706 0.63921569 0.42745098 0.51764706 0.85882353\n",
      " 0.57647059 0.64313725 0.89411765 0.58039216 0.64705882 0.88627451\n",
      " 0.57647059 0.64705882 0.90196078 0.56078431 0.63529412 0.88235294\n",
      " 0.68627451 0.66666667 0.70980392 0.         0.         0.\n",
      " 0.53333333 0.60392157 0.71372549 0.8        0.80784314 0.8745098\n",
      " 0.9254902  0.81960784 0.78431373 0.93333333 0.78431373 0.72156863\n",
      " 0.93333333 0.80392157 0.75686275 0.89019608 0.78823529 0.75686275\n",
      " 0.73333333 0.70980392 0.75294118 0.         0.         0.\n",
      " 0.76862745 0.69019608 0.65098039 0.92156863 0.78039216 0.71372549\n",
      " 0.96470588 0.64705882 0.54117647 0.95294118 0.61568627 0.50588235\n",
      " 0.96470588 0.63529412 0.53333333 0.9254902  0.6        0.50196078\n",
      " 0.61960784 0.57647059 0.70980392 0.         0.         0.\n",
      " 0.69411765 0.69411765 0.7372549  0.82745098 0.79215686 0.81176471\n",
      " 0.89411765 0.56078431 0.49803922 0.89019608 0.51372549 0.43529412\n",
      " 0.90588235 0.5372549  0.45882353 0.87058824 0.50588235 0.43137255\n",
      " 0.4745098  0.40392157 0.61568627 0.         0.         0.\n",
      " 0.33333333 0.66666667 0.66666667 0.69411765 0.7372549  0.78039216\n",
      " 0.76862745 0.49803922 0.45882353 0.71372549 0.39215686 0.35686275\n",
      " 0.76862745 0.45882353 0.38431373 0.74901961 0.41568627 0.37254902\n",
      " 0.33333333 0.16470588 0.33333333 0.         0.         0.        ]\n",
      "type X_train <class 'numpy.ndarray'>\n",
      "Dimension X_train (320, 192)\n",
      "\n",
      "\n",
      "Sur le dataset de Train\n",
      "0   0.07390830665826797\n",
      "1   0.07390830665826797\n",
      "2   0.07390830665826797\n",
      "3   0.07390830665826797\n",
      "4   0.07390830665826797\n",
      "5   0.07390830665826797\n",
      "6   0.07390830665826797\n",
      "7   0.07390830665826797\n",
      "8   0.07390830665826797\n",
      "9   0.07390830665826797\n",
      "10   0.07390830665826797\n",
      "11   0.07390830665826797\n",
      "12   0.07390830665826797\n",
      "13   0.07390830665826797\n",
      "14   0.07390830665826797\n",
      "15   0.07390830665826797\n",
      "16   0.07390830665826797\n",
      "17   0.07390830665826797\n",
      "18   0.07390830665826797\n",
      "19   0.07390830665826797\n",
      "20   0.07390830665826797\n",
      "21   0.07390830665826797\n",
      "22   0.07390830665826797\n",
      "23   0.07390830665826797\n",
      "24   0.07390830665826797\n",
      "25   0.07390830665826797\n",
      "26   0.07390830665826797\n",
      "27   0.07390830665826797\n",
      "28   0.07390830665826797\n",
      "29   0.07390830665826797\n",
      "30   0.07390830665826797\n",
      "31   0.07390830665826797\n",
      "32   0.07390830665826797\n",
      "33   0.07390830665826797\n",
      "34   0.07390830665826797\n",
      "35   0.07390830665826797\n",
      "36   0.07390830665826797\n",
      "37   0.07390830665826797\n",
      "38   0.07390830665826797\n",
      "39   0.07390830665826797\n",
      "40   0.07390830665826797\n",
      "41   0.07390830665826797\n",
      "42   0.07390830665826797\n",
      "43   0.07390830665826797\n",
      "44   0.07390830665826797\n",
      "45   0.07390830665826797\n",
      "46   0.07390830665826797\n",
      "47   0.07390830665826797\n",
      "48   0.07390830665826797\n",
      "49   0.07390830665826797\n",
      "50   0.07390830665826797\n",
      "51   0.07390830665826797\n",
      "52   0.07390830665826797\n",
      "53   0.07390830665826797\n",
      "54   0.07390830665826797\n",
      "55   0.07390830665826797\n",
      "56   0.07390830665826797\n",
      "57   0.07390830665826797\n",
      "58   0.07390830665826797\n",
      "59   0.07390830665826797\n",
      "60   0.07390830665826797\n",
      "61   0.07390830665826797\n",
      "62   0.07390830665826797\n",
      "63   0.07390830665826797\n",
      "64   0.07390830665826797\n",
      "65   0.07390830665826797\n",
      "66   0.07390830665826797\n",
      "67   0.07390830665826797\n",
      "68   0.07390830665826797\n",
      "69   0.07390830665826797\n",
      "70   0.07390830665826797\n",
      "71   0.07390830665826797\n",
      "72   0.07390830665826797\n",
      "73   0.07390830665826797\n",
      "74   0.07390830665826797\n",
      "75   0.07390830665826797\n",
      "76   0.07390830665826797\n",
      "77   0.07390830665826797\n",
      "78   0.07390830665826797\n",
      "79   0.07390830665826797\n",
      "80   0.07390830665826797\n",
      "81   0.07390830665826797\n",
      "82   0.07390830665826797\n",
      "83   0.07390830665826797\n",
      "84   0.07390830665826797\n",
      "85   0.07390830665826797\n",
      "86   0.07390830665826797\n",
      "87   0.07390830665826797\n",
      "88   0.07390830665826797\n",
      "89   0.07390830665826797\n",
      "90   0.07390830665826797\n",
      "91   0.07390830665826797\n",
      "92   0.07390830665826797\n",
      "93   0.07390830665826797\n",
      "94   0.05348040163516998\n",
      "95   0.07390830665826797\n",
      "96   0.07390830665826797\n",
      "97   0.07390830665826797\n",
      "98   0.07390830665826797\n",
      "99   0.07390830665826797\n",
      "100   0.07390830665826797\n",
      "101   0.07390830665826797\n",
      "102   0.07390830665826797\n",
      "103   0.07390830665826797\n",
      "104   0.07390830665826797\n",
      "105   0.07390830665826797\n",
      "106   0.07390830665826797\n",
      "107   0.07390830665826797\n",
      "108   0.07390830665826797\n",
      "109   0.07390830665826797\n",
      "110   0.07390830665826797\n",
      "111   0.07390830665826797\n",
      "112   0.07390830665826797\n",
      "113   0.07390830665826797\n",
      "114   0.07390830665826797\n",
      "115   0.07390830665826797\n",
      "116   0.07390830665826797\n",
      "117   0.07390830665826797\n",
      "118   0.07390830665826797\n",
      "119   0.07390830665826797\n",
      "120   0.07390830665826797\n",
      "121   0.07390830665826797\n",
      "122   0.07390830665826797\n",
      "123   0.07390830665826797\n",
      "124   0.07390830665826797\n",
      "125   0.07390830665826797\n",
      "126   0.07390830665826797\n",
      "127   0.05348040163516998\n",
      "128   0.07390830665826797\n",
      "129   0.07390830665826797\n",
      "130   0.07390830665826797\n",
      "131   0.07390830665826797\n",
      "132   0.07390830665826797\n",
      "133   0.07390830665826797\n",
      "134   0.07390830665826797\n",
      "135   0.07390830665826797\n",
      "136   0.07390830665826797\n",
      "137   0.05348040163516998\n",
      "138   0.05348040163516998\n",
      "139   0.07390830665826797\n",
      "140   0.07390830665826797\n",
      "141   0.07390830665826797\n",
      "142   0.07390830665826797\n",
      "143   0.05348040163516998\n",
      "144   0.07390830665826797\n",
      "145   0.07390830665826797\n",
      "146   0.07390830665826797\n",
      "147   0.07390830665826797\n",
      "148   0.07390830665826797\n",
      "149   0.07390830665826797\n",
      "150   0.07390830665826797\n",
      "151   0.07390830665826797\n",
      "152   0.07390830665826797\n",
      "153   0.07390830665826797\n",
      "154   0.07390830665826797\n",
      "155   0.07390830665826797\n",
      "156   0.07390830665826797\n",
      "157   0.07390830665826797\n",
      "158   0.07390830665826797\n",
      "159   0.07390830665826797\n",
      "0   0.07390830665826797\n",
      "1   0.07390830665826797\n",
      "2   0.07390830665826797\n",
      "3   0.07390830665826797\n",
      "4   0.07390830665826797\n",
      "5   0.07390830665826797\n",
      "6   0.07390830665826797\n",
      "7   0.07390830665826797\n",
      "8   0.07390830665826797\n",
      "9   0.07390830665826797\n",
      "10   0.07390830665826797\n",
      "11   0.07390830665826797\n",
      "12   0.07390830665826797\n",
      "13   0.07390830665826797\n",
      "14   0.07390830665826797\n",
      "15   0.07390830665826797\n",
      "16   0.07390830665826797\n",
      "17   0.07390830665826797\n",
      "18   0.07390830665826797\n",
      "19   0.07390830665826797\n",
      "20   0.07390830665826797\n",
      "21   0.07390830665826797\n",
      "22   0.07390830665826797\n",
      "23   0.07390830665826797\n",
      "24   0.07390830665826797\n",
      "25   0.07390830665826797\n",
      "26   0.07390830665826797\n",
      "27   0.07390830665826797\n",
      "28   0.07390830665826797\n",
      "29   0.07390830665826797\n",
      "30   0.07390830665826797\n",
      "31   0.07390830665826797\n",
      "32   0.07390830665826797\n",
      "33   0.07390830665826797\n",
      "34   0.07390830665826797\n",
      "35   0.07390830665826797\n",
      "36   0.07390830665826797\n",
      "37   0.07390830665826797\n",
      "38   0.07390830665826797\n",
      "39   0.07390830665826797\n",
      "40   0.07390830665826797\n",
      "41   0.07390830665826797\n",
      "42   0.07390830665826797\n",
      "43   0.07390830665826797\n",
      "44   0.07390830665826797\n",
      "45   0.07390830665826797\n",
      "46   0.07390830665826797\n",
      "47   0.07390830665826797\n",
      "48   0.07390830665826797\n",
      "49   0.07390830665826797\n",
      "50   0.07390830665826797\n",
      "51   0.07390830665826797\n",
      "52   0.05348040163516998\n",
      "53   0.07390830665826797\n",
      "54   0.07390830665826797\n",
      "55   0.07390830665826797\n",
      "56   0.07390830665826797\n",
      "57   0.07390830665826797\n",
      "58   0.07390830665826797\n",
      "59   0.07390830665826797\n",
      "60   0.05348040163516998\n",
      "61   0.07390830665826797\n",
      "62   0.07390830665826797\n",
      "63   0.07390830665826797\n",
      "64   0.07390830665826797\n",
      "65   0.07390830665826797\n",
      "66   0.07390830665826797\n",
      "67   0.07390830665826797\n",
      "68   0.05348040163516998\n",
      "69   0.07390830665826797\n",
      "70   0.07390830665826797\n",
      "71   0.07390830665826797\n",
      "72   0.07390830665826797\n",
      "73   0.07390830665826797\n",
      "74   0.07390830665826797\n",
      "75   0.07390830665826797\n",
      "76   0.07390830665826797\n",
      "77   0.07390830665826797\n",
      "78   0.07390830665826797\n",
      "79   0.07390830665826797\n",
      "80   0.07390830665826797\n",
      "81   0.07390830665826797\n",
      "82   0.07390830665826797\n",
      "83   0.07390830665826797\n",
      "84   0.07390830665826797\n",
      "85   0.07390830665826797\n",
      "86   0.07390830665826797\n",
      "87   0.07390830665826797\n",
      "88   0.07390830665826797\n",
      "89   0.07390830665826797\n",
      "90   0.07390830665826797\n",
      "91   0.07390830665826797\n",
      "92   0.07390830665826797\n",
      "93   0.07390830665826797\n",
      "94   0.07390830665826797\n",
      "95   0.05348040163516998\n",
      "96   0.07390830665826797\n",
      "97   0.07390830665826797\n",
      "98   0.07390830665826797\n",
      "99   0.07390830665826797\n",
      "100   0.07390830665826797\n",
      "101   0.07390830665826797\n",
      "102   0.07390830665826797\n",
      "103   0.07390830665826797\n",
      "104   0.07390830665826797\n",
      "105   0.07390830665826797\n",
      "106   0.07390830665826797\n",
      "107   0.07390830665826797\n",
      "108   0.07390830665826797\n",
      "109   0.07390830665826797\n",
      "110   0.07390830665826797\n",
      "111   0.07390830665826797\n",
      "112   0.07390830665826797\n",
      "113   0.07390830665826797\n",
      "114   0.07390830665826797\n",
      "115   0.07390830665826797\n",
      "116   0.07390830665826797\n",
      "117   0.07390830665826797\n",
      "118   0.07390830665826797\n",
      "119   0.07390830665826797\n",
      "120   0.07390830665826797\n",
      "121   0.07390830665826797\n",
      "122   0.07390830665826797\n",
      "123   0.07390830665826797\n",
      "124   0.07390830665826797\n",
      "125   0.07390830665826797\n",
      "126   0.07390830665826797\n",
      "127   0.07390830665826797\n",
      "128   0.07390830665826797\n",
      "129   0.05348040163516998\n",
      "130   0.07390830665826797\n",
      "131   0.07390830665826797\n",
      "132   0.07390830665826797\n",
      "133   0.07390830665826797\n",
      "134   0.07390830665826797\n",
      "135   0.07390830665826797\n",
      "136   0.07390830665826797\n",
      "137   0.05348040163516998\n",
      "138   0.07390830665826797\n",
      "139   0.07390830665826797\n",
      "140   0.07390830665826797\n",
      "141   0.07390830665826797\n",
      "142   0.07390830665826797\n",
      "143   0.07390830665826797\n",
      "144   0.07390830665826797\n",
      "145   0.07390830665826797\n",
      "146   0.07390830665826797\n",
      "147   0.07390830665826797\n",
      "148   0.07390830665826797\n",
      "149   0.07390830665826797\n",
      "150   0.07390830665826797\n",
      "151   0.07390830665826797\n",
      "152   0.07390830665826797\n",
      "153   0.07390830665826797\n",
      "154   0.07390830665826797\n",
      "155   0.07390830665826797\n",
      "156   0.05348040163516998\n",
      "157   0.07390830665826797\n",
      "158   0.07390830665826797\n",
      "159   0.07390830665826797\n"
     ]
    }
   ],
   "source": [
    "run_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b995eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur le dataset de Train\n",
      "0   -1.0\n",
      "1   -1.0\n",
      "2   -1.0\n",
      "3   -1.0\n",
      "4   -1.0\n",
      "5   -1.0\n",
      "6   -1.0\n",
      "7   -1.0\n",
      "8   -1.0\n",
      "9   -1.0\n",
      "10   -1.0\n",
      "11   -1.0\n",
      "12   -1.0\n",
      "13   -1.0\n",
      "14   -1.0\n",
      "15   -1.0\n",
      "16   -1.0\n",
      "17   -1.0\n",
      "18   -1.0\n",
      "19   -1.0\n",
      "20   -1.0\n",
      "21   -1.0\n",
      "22   -1.0\n",
      "23   -1.0\n",
      "24   -1.0\n",
      "25   -1.0\n",
      "26   -1.0\n",
      "27   -1.0\n",
      "28   -1.0\n",
      "29   -1.0\n",
      "30   -1.0\n",
      "31   -1.0\n",
      "32   -1.0\n",
      "33   -1.0\n",
      "34   -1.0\n",
      "35   -1.0\n",
      "36   -1.0\n",
      "37   -1.0\n",
      "38   -1.0\n",
      "39   -1.0\n",
      "40   -1.0\n",
      "41   -1.0\n",
      "42   -1.0\n",
      "43   -1.0\n",
      "44   -1.0\n",
      "45   -1.0\n",
      "46   -1.0\n",
      "47   -1.0\n",
      "48   -1.0\n",
      "49   -1.0\n",
      "50   -1.0\n",
      "51   -1.0\n",
      "52   -1.0\n",
      "53   -1.0\n",
      "54   -1.0\n",
      "55   -1.0\n",
      "56   -1.0\n",
      "57   -1.0\n",
      "58   -1.0\n",
      "59   -1.0\n",
      "60   -1.0\n",
      "61   -1.0\n",
      "62   -1.0\n",
      "63   -1.0\n",
      "64   -1.0\n",
      "65   -1.0\n",
      "66   -1.0\n",
      "67   -1.0\n",
      "68   -1.0\n",
      "69   -1.0\n",
      "70   -1.0\n",
      "71   -1.0\n",
      "72   -1.0\n",
      "73   -1.0\n",
      "74   -1.0\n",
      "75   -1.0\n",
      "76   -1.0\n",
      "77   -1.0\n",
      "78   -1.0\n",
      "79   -1.0\n",
      "80   -1.0\n",
      "81   -1.0\n",
      "82   -1.0\n",
      "83   -1.0\n",
      "84   -1.0\n",
      "85   -1.0\n",
      "86   -1.0\n",
      "87   -1.0\n",
      "88   -1.0\n",
      "89   -1.0\n",
      "90   -1.0\n",
      "91   -1.0\n",
      "92   -1.0\n",
      "93   -1.0\n",
      "94   -1.0\n",
      "95   -1.0\n",
      "96   -1.0\n",
      "97   -1.0\n",
      "98   -1.0\n",
      "99   -1.0\n",
      "100   -1.0\n",
      "101   -1.0\n",
      "102   -1.0\n",
      "103   -1.0\n",
      "104   -1.0\n",
      "105   -1.0\n",
      "106   -1.0\n",
      "107   -1.0\n",
      "108   -1.0\n",
      "109   -1.0\n",
      "110   -1.0\n",
      "111   -1.0\n",
      "112   -1.0\n",
      "113   -1.0\n",
      "114   -1.0\n",
      "115   -1.0\n",
      "116   -1.0\n",
      "117   -1.0\n",
      "118   -1.0\n",
      "119   -1.0\n",
      "120   -1.0\n",
      "121   -1.0\n",
      "122   -1.0\n",
      "123   -1.0\n",
      "124   -1.0\n",
      "125   -1.0\n",
      "126   -1.0\n",
      "127   -1.0\n",
      "128   -1.0\n",
      "129   -1.0\n",
      "130   -1.0\n",
      "131   -1.0\n",
      "132   -1.0\n",
      "133   -1.0\n",
      "134   -1.0\n",
      "135   -1.0\n",
      "136   -1.0\n",
      "137   -1.0\n",
      "138   -1.0\n",
      "139   -1.0\n",
      "140   -1.0\n",
      "141   -1.0\n",
      "142   -1.0\n",
      "143   -1.0\n",
      "144   -1.0\n",
      "145   -1.0\n",
      "146   -1.0\n",
      "147   -1.0\n",
      "148   -1.0\n",
      "149   -1.0\n",
      "150   -1.0\n",
      "151   -1.0\n",
      "152   -1.0\n",
      "153   -1.0\n",
      "154   -1.0\n",
      "155   -1.0\n",
      "156   -1.0\n",
      "157   -1.0\n",
      "158   -1.0\n",
      "159   -1.0\n",
      "0   -1.0\n",
      "1   -1.0\n",
      "2   -1.0\n",
      "3   -1.0\n",
      "4   -1.0\n",
      "5   -1.0\n",
      "6   -1.0\n",
      "7   -1.0\n",
      "8   -1.0\n",
      "9   -1.0\n",
      "10   -1.0\n",
      "11   -1.0\n",
      "12   -1.0\n",
      "13   -1.0\n",
      "14   -1.0\n",
      "15   -1.0\n",
      "16   -1.0\n",
      "17   -1.0\n",
      "18   -1.0\n",
      "19   -1.0\n",
      "20   -1.0\n",
      "21   -1.0\n",
      "22   -1.0\n",
      "23   -1.0\n",
      "24   -1.0\n",
      "25   -1.0\n",
      "26   -1.0\n",
      "27   -1.0\n",
      "28   -1.0\n",
      "29   -1.0\n",
      "30   -1.0\n",
      "31   -1.0\n",
      "32   -1.0\n",
      "33   -1.0\n",
      "34   -1.0\n",
      "35   -1.0\n",
      "36   -1.0\n",
      "37   -1.0\n",
      "38   -1.0\n",
      "39   -1.0\n",
      "40   -1.0\n",
      "41   -1.0\n",
      "42   -1.0\n",
      "43   -1.0\n",
      "44   -1.0\n",
      "45   -1.0\n",
      "46   -1.0\n",
      "47   -1.0\n",
      "48   -1.0\n",
      "49   -1.0\n",
      "50   -1.0\n",
      "51   -1.0\n",
      "52   -1.0\n",
      "53   -1.0\n",
      "54   -1.0\n",
      "55   -1.0\n",
      "56   -1.0\n",
      "57   -1.0\n",
      "58   -1.0\n",
      "59   -1.0\n",
      "60   -1.0\n",
      "61   -1.0\n",
      "62   -1.0\n",
      "63   -1.0\n",
      "64   -1.0\n",
      "65   -1.0\n",
      "66   -1.0\n",
      "67   -1.0\n",
      "68   -1.0\n",
      "69   -1.0\n",
      "70   -1.0\n",
      "71   -1.0\n",
      "72   -1.0\n",
      "73   -1.0\n",
      "74   -1.0\n",
      "75   -1.0\n",
      "76   -1.0\n",
      "77   -1.0\n",
      "78   -1.0\n",
      "79   -1.0\n",
      "80   -1.0\n",
      "81   -1.0\n",
      "82   -1.0\n",
      "83   -1.0\n",
      "84   -1.0\n",
      "85   -1.0\n",
      "86   -1.0\n",
      "87   -1.0\n",
      "88   -1.0\n",
      "89   -1.0\n",
      "90   -1.0\n",
      "91   -1.0\n",
      "92   -1.0\n",
      "93   -1.0\n",
      "94   -1.0\n",
      "95   -1.0\n",
      "96   -1.0\n",
      "97   -1.0\n",
      "98   -1.0\n",
      "99   -1.0\n",
      "100   -1.0\n",
      "101   -1.0\n",
      "102   -1.0\n",
      "103   -1.0\n",
      "104   -1.0\n",
      "105   -1.0\n",
      "106   -1.0\n",
      "107   -1.0\n",
      "108   -1.0\n",
      "109   -1.0\n",
      "110   -1.0\n",
      "111   -1.0\n",
      "112   -1.0\n",
      "113   -1.0\n",
      "114   -1.0\n",
      "115   -1.0\n",
      "116   -1.0\n",
      "117   -1.0\n",
      "118   -1.0\n",
      "119   -1.0\n",
      "120   -1.0\n",
      "121   -1.0\n",
      "122   -1.0\n",
      "123   -1.0\n",
      "124   -1.0\n",
      "125   -1.0\n",
      "126   -1.0\n",
      "127   -1.0\n",
      "128   -1.0\n",
      "129   -1.0\n",
      "130   -1.0\n",
      "131   -1.0\n",
      "132   -1.0\n",
      "133   -1.0\n",
      "134   -1.0\n",
      "135   -1.0\n",
      "136   -1.0\n",
      "137   -1.0\n",
      "138   -1.0\n",
      "139   -1.0\n",
      "140   -1.0\n",
      "141   -1.0\n",
      "142   -1.0\n",
      "143   -1.0\n",
      "144   -1.0\n",
      "145   -1.0\n",
      "146   -1.0\n",
      "147   -1.0\n",
      "148   -1.0\n",
      "149   -1.0\n",
      "150   -1.0\n",
      "151   -1.0\n",
      "152   -1.0\n",
      "153   -1.0\n",
      "154   -1.0\n",
      "155   -1.0\n",
      "156   -1.0\n",
      "157   -1.0\n",
      "158   -1.0\n",
      "159   -1.0\n"
     ]
    }
   ],
   "source": [
    "run_linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48321ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
