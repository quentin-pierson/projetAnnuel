{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ccd207",
   "metadata": {},
   "source": [
    "# <center> <span style=\"color:red\">Music recognition </span> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440cabe",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to take in music spectrograms and to recognize musical genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b6ec6",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3faa6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb785e99",
   "metadata": {},
   "source": [
    "## Import Model Linear and MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7621ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../../python')\n",
    "\n",
    "from linearModel import linearModel\n",
    "from mlp import MLPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ccd7c3",
   "metadata": {},
   "source": [
    "## Create Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b047493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linearModel()\n",
    "mlp = MLPModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd54240",
   "metadata": {},
   "source": [
    "## Algorithme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f50c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_images_and_assign_labels(\n",
    "        folder, label, X, Y):\n",
    "    for file in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file)\n",
    "        im = Image.open(image_path)\n",
    "        im = im.resize((8, 8))\n",
    "        im = im.convert(\"RGB\")\n",
    "        im_arr = np.array(im)\n",
    "        im_arr = np.reshape(im_arr, (8 * 8 * 3))\n",
    "        X.append(im_arr)\n",
    "        Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8223667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset():\n",
    "    dataset_folder = \"G:/Programmes/Python/projetAnnuel/data\"\n",
    "    train_folder = os.path.join(dataset_folder, \"train\")\n",
    "    test_folder = os.path.join(dataset_folder, \"test\")\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    import_images_and_assign_labels(\n",
    "        os.path.join(train_folder, \"Electro\"), 1.0, X_train, y_train\n",
    "    )\n",
    "    import_images_and_assign_labels(\n",
    "        os.path.join(train_folder, \"Metal\"), -1.0, X_train, y_train\n",
    "    )\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    import_images_and_assign_labels(\n",
    "        os.path.join(test_folder, \"Electro\"), 1.0, X_test, y_test\n",
    "    )\n",
    "    import_images_and_assign_labels(\n",
    "        os.path.join(test_folder, \"Metal\"), -1.0, X_test, y_test\n",
    "    )\n",
    "\n",
    "    return (np.array(X_train) / 255.0, np.array(y_train)), \\\n",
    "           (np.array(X_test) / 255.0, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "523bd7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp():\n",
    "    (X_train, y_train), (X_test, y_test) = import_dataset()\n",
    "    \n",
    "    resultat1 = mlp.create_mlp_model([2,4,4,1])\n",
    "    model1 = resultat1[0]\n",
    "       \n",
    "    predicted_outputs = [mlp.predict_mlp_model_classification(model1, p) for p in X_train]\n",
    "\n",
    "    flattened_dataset_inputs = []\n",
    "    for p in X_train:\n",
    "        flattened_dataset_inputs.append(p[0])\n",
    "        flattened_dataset_inputs.append(p[1])\n",
    "        \n",
    "    print(\"flattened_dataset_inputs\",flattened_dataset_inputs)\n",
    "    \n",
    "    print(\"X_train\",X_train)\n",
    "    \n",
    "    mlp.train_classification_stochastic_gradient_backpropagation(model1,\n",
    "                                                                flattened_dataset_inputs,\n",
    "                                                                y_train,\n",
    "                                                                alpha=0.01,\n",
    "                                                                iterations_count=6500)\n",
    "\n",
    "    predicted_outputs = [mlp.predict_mlp_model_classification(model1, p) for p in X_train]\n",
    "       \n",
    "    print(\"Sur le dataset de Train\")\n",
    "    cpt = 0\n",
    "    for i in predicted_outputs:\n",
    "        print(cpt,\" \",i)\n",
    "        cpt+=1\n",
    "    #out = [print(i) for i in predicted_outputs]\n",
    "    #print(predicted_outputs,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c373ecdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened_dataset_inputs [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0]\n",
      "X_train [[0.33333333 0.33333333 0.66666667 ... 0.         0.         0.        ]\n",
      " [0.33333333 0.33333333 0.66666667 ... 0.         0.         0.        ]\n",
      " [0.33333333 0.33333333 0.66666667 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.33333333 0.33333333 0.66666667 ... 0.         0.         0.        ]\n",
      " [0.33333333 0.33333333 0.66666667 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "Sur le dataset de Train\n",
      "0   -0.11824516952037811\n",
      "1   -0.11824516952037811\n",
      "2   -0.11824516952037811\n",
      "3   -0.11824516952037811\n",
      "4   -0.11824516952037811\n",
      "5   -0.11824516952037811\n",
      "6   -0.11824516952037811\n",
      "7   -0.11824516952037811\n",
      "8   -0.11824516952037811\n",
      "9   -0.11824516952037811\n",
      "10   -0.11824516952037811\n",
      "11   -0.11824516952037811\n",
      "12   -0.11824516952037811\n",
      "13   -0.11824516952037811\n",
      "14   -0.11824516952037811\n",
      "15   -0.11824516952037811\n",
      "16   -0.11824516952037811\n",
      "17   -0.11824516952037811\n",
      "18   -0.11824516952037811\n",
      "19   -0.11824516952037811\n",
      "20   -0.11824516952037811\n",
      "21   -0.11824516952037811\n",
      "22   -0.11824516952037811\n",
      "23   -0.11824516952037811\n",
      "24   -0.11824516952037811\n",
      "25   -0.11824516952037811\n",
      "26   -0.11824516952037811\n",
      "27   -0.11824516952037811\n",
      "28   -0.11824516952037811\n",
      "29   -0.11824516952037811\n",
      "30   -0.11824516952037811\n",
      "31   -0.11824516952037811\n",
      "32   -0.11824516952037811\n",
      "33   -0.11824516952037811\n",
      "34   0.12266339361667633\n",
      "35   -0.11824516952037811\n",
      "36   -0.11824516952037811\n",
      "37   -0.11824516952037811\n",
      "38   -0.11824516952037811\n",
      "39   -0.11824516952037811\n",
      "40   -0.11824516952037811\n",
      "41   -0.11824516952037811\n",
      "42   -0.11824516952037811\n",
      "43   -0.11824516952037811\n",
      "44   -0.11824516952037811\n",
      "45   -0.11824516952037811\n",
      "46   -0.11824516952037811\n",
      "47   0.12266339361667633\n",
      "48   0.12266339361667633\n",
      "49   -0.11824516952037811\n",
      "50   -0.11824516952037811\n",
      "51   -0.11824516952037811\n",
      "52   -0.11824516952037811\n",
      "53   -0.11824516952037811\n",
      "54   -0.11824516952037811\n",
      "55   -0.11824516952037811\n",
      "56   -0.11824516952037811\n",
      "57   -0.11824516952037811\n",
      "58   -0.11824516952037811\n",
      "59   -0.11824516952037811\n",
      "60   -0.11824516952037811\n",
      "61   -0.8632911443710327\n",
      "62   -0.8632911443710327\n",
      "63   -0.8632911443710327\n",
      "64   -0.8632911443710327\n",
      "65   -0.8632911443710327\n",
      "66   -0.8632911443710327\n",
      "67   -0.8632911443710327\n",
      "68   -0.8632911443710327\n",
      "69   -0.8632911443710327\n",
      "70   -0.11824516952037811\n",
      "71   0.12266339361667633\n",
      "72   -0.11824516952037811\n",
      "73   -0.11824516952037811\n",
      "74   -0.11824516952037811\n",
      "75   -0.11824516952037811\n",
      "76   -0.11824516952037811\n",
      "77   -0.11824516952037811\n",
      "78   -0.11824516952037811\n",
      "79   -0.11824516952037811\n",
      "80   -0.11824516952037811\n",
      "81   -0.11824516952037811\n",
      "82   -0.11824516952037811\n",
      "83   -0.11824516952037811\n",
      "84   -0.11824516952037811\n",
      "85   -0.11824516952037811\n",
      "86   -0.11824516952037811\n",
      "87   -0.11824516952037811\n",
      "88   -0.11824516952037811\n",
      "89   -0.11824516952037811\n",
      "90   -0.11824516952037811\n",
      "91   -0.11824516952037811\n",
      "92   -0.11824516952037811\n",
      "93   -0.11824516952037811\n",
      "94   -0.11824516952037811\n",
      "95   -0.11824516952037811\n",
      "96   -0.11824516952037811\n",
      "97   -0.11824516952037811\n",
      "98   0.12266339361667633\n"
     ]
    }
   ],
   "source": [
    "run_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b995eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
